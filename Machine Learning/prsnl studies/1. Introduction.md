T. Mitchell’s book “Machine Learning” (1997) gives a classic, general definition of machine learning as follows:

> A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P, if its performance at tasks in T, as measured by P, improves with experience E.

In the various problem settings T, P, and E can refer to completely different things.

Some of the most popular tasks T in machine learning are the following:

- classification of an instance to one of the categories based on its features.
- regression – prediction of a numerical target feature based on other features of an instance.
- clustering – identifying partitions of instances based on the features of these instances so that the members within the groups are more similar to each other than those in the other groups.
- anomaly detection – search for instances that are “greatly dissimilar” to the rest of the sample or to some group of instances.
- and so many more.

Experience E refers to data. Machine learning algorithms can be divided into those that are trained in supervised or unsupervised manner. 

In unsupervised learning tasks, one has a set consisting of instances described by a set of features. In supervised learning problems, there’s also a target variable, which is what we would like to be able to predict, known for each instance in a training set.

Finally, the third term used in the definition of machine learning is a metric of the algorithm’s performance evaluation P. Such metrics differ for various problems and algorithms, and we’ll discuss them as we study new algorithms.